{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WE5GJ6s7y0Xo"
   },
   "source": [
    "## Research Project  -  Unimodal Prompt Engineering examples - Kruti Shah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfBzP8gWzkpv"
   },
   "source": [
    "### Install requirements\n",
    "\n",
    "First, run the cells below to install the requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyYOfCjFGXDf",
    "outputId": "4837d4bd-f2e9-477e-c4af-d9bd15da5196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.29.0 in /usr/local/lib/python3.10/dist-packages (4.29.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.29.0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.29.0) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.29.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.29.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.29.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.29.0) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.29.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOtwYRI3zzXI"
   },
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451,
     "referenced_widgets": [
      "aacba92421964c48880ebcc912869e8a",
      "5d94f0fa171043f99b011e64e474b690",
      "e26371ac866c4d7f848b300b8b24fad2",
      "6c71914bd40442e8898115539681ab5b",
      "e42a2bd2a1ff4c3288ff4c2e782e3bd9",
      "86d8060e9708458ab8058880545becf0",
      "ba701e2b2b52447fbf67ff8fa52b14d2",
      "6706a24659b34bfa9e79e9573731b9de",
      "5c404e36057142dea03f46506d13feda",
      "cc8fec2db4e24012876bf755976553df",
      "eb632e98f20743e88dea38773dc3b237"
     ]
    },
    "id": "T8bvrsaLUxCY",
    "outputId": "d1886f26-7135-402a-87cc-d6aac3a2a218"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "WARNING:transformers_modules.tiiuae.falcon-7b-instruct.cf4b3c42ce2fdfe24f753f0f0d179202fea59c99.configuration_falcon:\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aacba92421964c48880ebcc912869e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "The model 'FalconForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\n",
      "Daniel: Hello, Girafatron!\n",
      "Girafatron: Ah, Daniel! It's so nice of you to join the discussion.\n",
      "Daniel: So, what would you name your first giraffe? (Girafatron smiles) How about Girafafatron? Would it be a silly name?\n",
      "Girafafatron: It's not a silly name. In fact, it's a very interesting name, Daniel. I believe it fits me perfectly!\n",
      "Daniel: Oh, I see. How about you, Girafatron? What is your name?\n",
      "Giraftron: My name is Girafatron!\n",
      "Daniel: \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, torch_dtype=torch.bfloat16)\n",
    "\n",
    "# Set configurations\n",
    "model.config.max_length = 512\n",
    "model.config.truncation = True\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Fix the issue by setting _lock to None\n",
    "model.config._lock = None\n",
    "\n",
    "# Define text generation pipeline\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Generate text\n",
    "sequences = text_generator(\n",
    "    \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "3f789412f0bc45c2872b4bfef2b88752",
      "22cfe32dcc7243589bd192422c2b0d9b",
      "62890eaaa6e241d9bc730d7301966456",
      "af41712afee04270aac2fdaf2dd171fd",
      "2641441bf3874b39b4542e12aa22c88a",
      "780917b71df2484498720ad3d884ff86",
      "026fb1cacda84b4b8513ba3a1e111b2e",
      "599db9d1755049b39948ee3be4610293",
      "6bb559f76e4f495fba3154e1e8435300",
      "f077a2f7139c46db91e9c8aa5d4da895",
      "1faae2b47c8f46bbb57ebebab49f0f45"
     ]
    },
    "id": "qovSDLDWxYyE",
    "outputId": "be91fe00-79a1-42f2-a18e-c2773419a413"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f789412f0bc45c2872b4bfef2b88752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'FalconForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Classify the text into neutral, negative or positive.\n",
      "Text: This movie is definitely one of my favorite movies of its kind. The interaction between respectable and morally strong characters is an ode to chivalry and the honor code amongst thieves and policemen.\n",
      "Sentiment:\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "#from transformers import pipeline, AutoTokenizer\n",
    "#import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForCausalLM.from_pretrained(model)\n",
    "model.config.max_length = 512\n",
    "model.config.truncation = True\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "'''\n",
    "pipe = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "\n",
    ")\n",
    "torch.manual_seed(0)\n",
    "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
    "Text: This movie is definitely one of my favorite movies of its kind. The interaction between respectable and morally strong characters is an ode to chivalry and the honor code amongst thieves and policemen.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=10,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MfH8vxSI0c5"
   },
   "source": [
    "### Sentiment Analysis example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z73H71jqI8nF",
    "outputId": "0b41ffce-da29-45aa-8492-7325fefc5fc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Classify the text into neutral, negative or positive.\n",
      "Text: \"Indian Delights impressed me with impeccable customer service, attentive staff, and a warm welcome. The food was a culinary masterpiece, bursting with flavor and creativity, while the ambience added to the enchanting dining experience.\n",
      "Sentiment:\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
    "Text: \"Indian Delights impressed me with impeccable customer service, attentive staff, and a warm welcome. The food was a culinary masterpiece, bursting with flavor and creativity, while the ambience added to the enchanting dining experience.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=10,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39tUuTbZI-oc"
   },
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1wn62zAJHXx",
    "outputId": "7a264d0b-e848-4a35-cd4f-eb83afb7e28e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \"Classify the following text as either 'Sports', 'Politics', or 'Entertainment':\n",
      "Text: 'The latest game between Team A and Team B ended in a thrilling tiebreaker, leaving fans on the edge of their seats.'\"\n",
      "Sentiment:\n",
      "The sentiment of the text is 'Sports'.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "prompt = \"\"\"\"Classify the following text as either 'Sports', 'Politics', or 'Entertainment':\n",
    "Text: 'The latest game between Team A and Team B ended in a thrilling tiebreaker, leaving fans on the edge of their seats.'\"\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=10,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22u8Emq8JJ_x"
   },
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNuxR6anJZgj",
    "outputId": "d49547c7-f158-45f6-ead4-6b6b5664c80d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Golden Gate Bridge\n",
      "- San Francisco Bay area\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "prompt = \"\"\"Return a list of named entities in the text.\n",
    "Text: The Golden Gate Bridge spans the San Francisco Bay area.\n",
    "Named entities:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=15,\n",
    "    return_full_text = False,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_Q7wZYGJouS"
   },
   "source": [
    "### Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szA3wdziJqze",
    "outputId": "4bf6bd77-f718-498e-b8a6-979ed3737057"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il sole si allunga dietro ai monti, proiettando una calma luce sulla tranquilla\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "prompt = \"\"\"Translate the English text to Italian.\n",
    "Text: \"The sun sets behind the mountains, casting a warm glow over the tranquil valley below.\"\n",
    "Translation:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=20,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    return_full_text = False,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnCug4XTJ_5G"
   },
   "source": [
    "### Text Summarization example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJUnrk2QKeyl",
    "outputId": "9d3b977f-eb09-4019-e09f-919a5b34417f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Diwali is a significant annual celebration of the Hindu faith.\n",
      "- It is marked by colorful traditions, prayers, and feasts.\n",
      "- The festival symbolizes the victory of light over darkness and good over evil.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "prompt = \"\"\"Diwali, also known as the Festival of Lights, is one of the most significant Hindu festivals celebrated world-wide\n",
    "Write a summary of the above text.\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "prompt,\n",
    "max_new_tokens=50,\n",
    "do_sample=True,\n",
    "top_k=10,\n",
    "return_full_text = False,\n",
    "\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Summarization example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5pVOiIaaVIw",
    "outputId": "e22e7247-0e8f-4ee0-e341-265551d7f00b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Diwali is a major Hindu festival celebrated around the world, involving colorful traditions, food, and fireworks.\n",
      "2. The festival is celebrated in India and other countries with various types of decorations, lights, and sweets, and is typically accompanied\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "prompt = \"\"\"Diwali, also known as the Festival of Lights, is one of the most significant Hindu festivals celebrated world\n",
    "Summarize the above text in 2 sentences\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "prompt,\n",
    "max_new_tokens=50,\n",
    "do_sample=True,\n",
    "top_k=10,\n",
    "return_full_text = False,\n",
    "\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question- Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fi3IZxz2it9M",
    "outputId": "d8cae70f-ca55-4dae-ef9a-4d6bb10d6bc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 1. Prioritize tasks based on urgency and importance.\n",
      "2. Use a to-do list to keep tasks organized.\n",
      "3. Set specific deadlines for tasks to ensure progress.\n",
      "4. Break complex tasks into smaller, more manageable chunks.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(4)\n",
    "prompt = \"\"\"What are some effective strategies for improving time management skills in a busy work environment?\".\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    return_full_text = False,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G6nL6orvoJ7"
   },
   "source": [
    "### Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZrYJn04vkxb",
    "outputId": "276c5946-ca93-4903-eade-849abb441710"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "John has 3 apples left.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "prompt = \"\"\"If John has 5 apples and he gives 2 apples to his friend Sarah, how many apples does John have left?\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "prompt,\n",
    "max_new_tokens=30,\n",
    "do_sample=True,\n",
    "top_k=10,\n",
    "return_full_text = False,\n",
    ")\n",
    "for seq in sequences:\n",
    "  print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k70sAliv-rK"
   },
   "source": [
    "### Few-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJy77CmXv3wJ",
    "outputId": "65f6ebce-4e18-422a-e435-7d5d6c13c5c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1: Instructions: Generate the next number in each sequence based on the given examples.\n",
      "Context: You are tutoring a student in arithmetic sequences and want to test their ability to identify the pattern and find the next number.\n",
      "Examples with Solutions:\n",
      "1. 2, 4, 6, __\n",
      "   Example solution: 8\n",
      "   \n",
      "2. 5, 10, 15, __\n",
      "   Example solution: 20  \n",
      "\n",
      "3. 3, 6, 9, __\n",
      "   Example solution: 12  \n",
      "\n",
      "4. 12, 9, 6, __\n",
      "   Example solution: 3  \n",
      "\n",
      "5. 20, 40, 60, __\n",
      "   Example solution: 80  \n",
      "\n",
      "6. 30, 60, 90, __\n",
      "   Example solution: 45\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6)\n",
    "\n",
    "prompt = \"\"\"\n",
    "Instructions: Generate the next number in each sequence based on the given examples.\n",
    "Context: You are tutoring a student in arithmetic sequences and want to test their ability to identify the pattern and find the next number.\n",
    "Examples with Solutions:\n",
    "1. 2, 4, 6, __\n",
    "   Example solution: 8\n",
    "\n",
    "2. 5, 10, 15, __\n",
    "   Example solution: 20\n",
    "\n",
    "3. 3, 6, 9, __\n",
    "   Example solution: 12\n",
    "\n",
    "4. 12, 9, 6, __\n",
    "   Example solution: 3\n",
    "\n",
    "5. 20, 40, 60, __\n",
    "   Example solution: 80\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=30,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    ")\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    print(f\"Sequence {i + 1}: {seq['generated_text'].strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxWbmWn0v7Cw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "026fb1cacda84b4b8513ba3a1e111b2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1faae2b47c8f46bbb57ebebab49f0f45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22cfe32dcc7243589bd192422c2b0d9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_780917b71df2484498720ad3d884ff86",
      "placeholder": "​",
      "style": "IPY_MODEL_026fb1cacda84b4b8513ba3a1e111b2e",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "2641441bf3874b39b4542e12aa22c88a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f789412f0bc45c2872b4bfef2b88752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22cfe32dcc7243589bd192422c2b0d9b",
       "IPY_MODEL_62890eaaa6e241d9bc730d7301966456",
       "IPY_MODEL_af41712afee04270aac2fdaf2dd171fd"
      ],
      "layout": "IPY_MODEL_2641441bf3874b39b4542e12aa22c88a"
     }
    },
    "599db9d1755049b39948ee3be4610293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c404e36057142dea03f46506d13feda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5d94f0fa171043f99b011e64e474b690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86d8060e9708458ab8058880545becf0",
      "placeholder": "​",
      "style": "IPY_MODEL_ba701e2b2b52447fbf67ff8fa52b14d2",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "62890eaaa6e241d9bc730d7301966456": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_599db9d1755049b39948ee3be4610293",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6bb559f76e4f495fba3154e1e8435300",
      "value": 2
     }
    },
    "6706a24659b34bfa9e79e9573731b9de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bb559f76e4f495fba3154e1e8435300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c71914bd40442e8898115539681ab5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc8fec2db4e24012876bf755976553df",
      "placeholder": "​",
      "style": "IPY_MODEL_eb632e98f20743e88dea38773dc3b237",
      "value": " 2/2 [00:20&lt;00:00,  8.96s/it]"
     }
    },
    "780917b71df2484498720ad3d884ff86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86d8060e9708458ab8058880545becf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aacba92421964c48880ebcc912869e8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d94f0fa171043f99b011e64e474b690",
       "IPY_MODEL_e26371ac866c4d7f848b300b8b24fad2",
       "IPY_MODEL_6c71914bd40442e8898115539681ab5b"
      ],
      "layout": "IPY_MODEL_e42a2bd2a1ff4c3288ff4c2e782e3bd9"
     }
    },
    "af41712afee04270aac2fdaf2dd171fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f077a2f7139c46db91e9c8aa5d4da895",
      "placeholder": "​",
      "style": "IPY_MODEL_1faae2b47c8f46bbb57ebebab49f0f45",
      "value": " 2/2 [00:11&lt;00:00,  5.17s/it]"
     }
    },
    "ba701e2b2b52447fbf67ff8fa52b14d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc8fec2db4e24012876bf755976553df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e26371ac866c4d7f848b300b8b24fad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6706a24659b34bfa9e79e9573731b9de",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c404e36057142dea03f46506d13feda",
      "value": 2
     }
    },
    "e42a2bd2a1ff4c3288ff4c2e782e3bd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb632e98f20743e88dea38773dc3b237": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f077a2f7139c46db91e9c8aa5d4da895": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
